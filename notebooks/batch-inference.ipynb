{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary reading of pilot llava results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>argument</th>\n",
       "      <th>substitution</th>\n",
       "      <th>exact_match/score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Is the curtain on the right side or on the lef...</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>curtain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Is the blind on the right side or on the left ...</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>curtain</td>\n",
       "      <td>blind</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Is the protective covering on the right side o...</td>\n",
       "      <td>left</td>\n",
       "      <td>right</td>\n",
       "      <td>curtain</td>\n",
       "      <td>protective covering</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Is the covering on the right side or on the le...</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>curtain</td>\n",
       "      <td>covering</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Is the cloth on the right side or on the left ...</td>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>curtain</td>\n",
       "      <td>cloth</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>Are there vertebrates in the photo that are no...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>zebra</td>\n",
       "      <td>vertebrate</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>Are there animals in the photo that are not st...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>zebra</td>\n",
       "      <td>animal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>Is the boy's hair curly and short?</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>Is the man's hair curly and short?</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>boy</td>\n",
       "      <td>man</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>Is the adult's hair curly and short?</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>boy</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                           question response  \\\n",
       "0            0  Is the curtain on the right side or on the lef...    right   \n",
       "1            1  Is the blind on the right side or on the left ...    right   \n",
       "2            2  Is the protective covering on the right side o...     left   \n",
       "3            3  Is the covering on the right side or on the le...    right   \n",
       "4            4  Is the cloth on the right side or on the left ...    right   \n",
       "..         ...                                                ...      ...   \n",
       "95          95  Are there vertebrates in the photo that are no...       no   \n",
       "96          96  Are there animals in the photo that are not st...       no   \n",
       "97          97                 Is the boy's hair curly and short?      yes   \n",
       "98          98                 Is the man's hair curly and short?      yes   \n",
       "99          99               Is the adult's hair curly and short?      yes   \n",
       "\n",
       "   reference argument         substitution  exact_match/score  \n",
       "0      right  curtain                  NaN                1.0  \n",
       "1      right  curtain                blind                1.0  \n",
       "2      right  curtain  protective covering                0.0  \n",
       "3      right  curtain             covering                1.0  \n",
       "4      right  curtain                cloth                1.0  \n",
       "..       ...      ...                  ...                ...  \n",
       "95        no    zebra           vertebrate                1.0  \n",
       "96        no    zebra               animal                1.0  \n",
       "97        no      boy                  NaN                0.0  \n",
       "98        no      boy                  man                0.0  \n",
       "99        no      boy                adult                0.0  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"llava-100-test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch inference with Gemma/PaliGemma with HF + GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemma is a family of lightweight, state-of-the-art open models built from the same research and technology used to create the Gemini models, developed by Google DeepMind and other teams across Google. Text Generation Inference (TGI) is a toolkit developed by Hugging Face for deploying and serving LLMs, with high performance text generation. And, Google Vertex AI is a Machine Learning (ML) platform that lets you train and deploy ML models and AI applications, and customize large language models (LLMs) for use in your AI-powered applications. This example showcases how to deploy any supported text-generation model, in this case [`google/gemma-7b-it`](https://huggingface.co/google/gemma-7b-it), from the Hugging Face Hub on Vertex AI using the TGI DLC available in Google Cloud Platform (GCP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![`google/gemma-7b-it` in the Hugging Face Hub](./assets/model-in-hf-hub.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup / Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to install `gcloud` in your local machine, which is the command-line tool for Google Cloud, following the instructions at [Cloud SDK Documentation - Install the gcloud CLI](https://cloud.google.com/sdk/docs/install)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you also need to install the `google-cloud-aiplatform` Python SDK, required to programmatically create the Vertex AI model, register it, acreate the endpoint, and deploy it on Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (1.70.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (5.28.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.18.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (1.12.5)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: docstring-parser<1 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from pydantic<3->google-cloud-aiplatform) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dali/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, to ease the usage of the commands within this tutorial, you need to set the following environment variables for GCP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROJECT_ID=multimodal-representations\n",
      "env: LOCATION=us-central1\n",
      "env: CONTAINER_URI=us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-generation-inference-cu124.2-3.ubuntu2204.py311\n"
     ]
    }
   ],
   "source": [
    "%env PROJECT_ID=multimodal-representations\n",
    "%env LOCATION=us-central1\n",
    "#%env CONTAINER_URI=us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-generation-inference-cu121.2-2.ubuntu2204.py310:latest\n",
    "#%env CONTAINER_URI=us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-llava-serve\n",
    "%env CONTAINER_URI=us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-generation-inference-cu124.2-3.ubuntu2204.py311\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you need to login into your GCP account and set the project ID to the one you want to use to register and deploy the models on Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=UI5PYdVu9zvqCQZuLdHsOugJBfCmSp&access_type=offline&code_challenge=pSxNv7rhVp3FaVp1G6BYDsJx4oJ3y-w8KRT9HIfLCOw&code_challenge_method=S256\n",
      "\n",
      "\n",
      "You are now logged in as [daliumuwork@gmail.com].\n",
      "Your current project is [multimodal-representations].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth login\n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are logged in, you need to enable the necessary service APIs in GCP, such as the Vertex AI API, the Compute Engine API, and Google Container Registry related APIs.\n",
    "\n",
    "**Warning:** Make sure, manually, that these are disabled after running exps (even though we will explicitly write code to disable them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com\n",
    "!gcloud services enable compute.googleapis.com\n",
    "!gcloud services enable container.googleapis.com\n",
    "!gcloud services enable containerregistry.googleapis.com\n",
    "!gcloud services enable containerfilesystem.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model on Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once everything is set up, you can already initialize the Vertex AI session via the `google-cloud-aiplatform` Python SDK as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(\n",
    "    project=os.getenv(\"PROJECT_ID\"),\n",
    "    location=os.getenv(\"LOCATION\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Gemma models are gated, you need to login into your Hugging Face Hub account with a read-access token either fine-grained with access to the gated model, or just overall read-access to your account. More information on how to generate a read-only access token for the Hugging Face Hub in the instructions at <https://huggingface.co/docs/hub/en/security-tokens>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your token (input will not be visible):  ········\n",
      "Add token as git credential? (Y/n)  n\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can already \"upload\" the model i.e. register the model on Vertex AI. It is not an upload per se, since the model will be automatically downloaded from the Hugging Face Hub in the Hugging Face DLC for TGI on startup via the `MODEL_ID` environment variable, so what is uploaded is only the configuration, not the model weights.\n",
    "\n",
    "Before going into the code, let's quickly review the arguments provided to the `upload` method:\n",
    "\n",
    "* **`display_name`** is the name that will be shown in the Vertex AI Model Registry.\n",
    "\n",
    "* **`serving_container_image_uri`** is the location of the Hugging Face DLC for TGI that will be used for serving the model.\n",
    "\n",
    "* **`serving_container_environment_variables`** are the environment variables that will be used during the container runtime, so these are aligned with the environment variables defined by `text-generation-inference`, which are analog to the [`text-generation-launcher` arguments](https://huggingface.co/docs/text-generation-inference/en/basic_tutorials/launcher). Additionally, the Hugging Face DLCs for TGI also capture the `AIP_` environment variables from Vertex AI as in [Vertex AI Documentation - Custom container requirements for prediction](https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements).\n",
    "\n",
    "    * `MODEL_ID` is the identifier of the model in the Hugging Face Hub. To explore all the supported models you can check <https://huggingface.co/models?sort=trending&other=text-generation-inference>.\n",
    "    * `NUM_SHARD` is the number of shards to use if you don't want to use all GPUs on a given machine e.g. if you have two GPUs but you just want to use one for TGI then `NUM_SHARD=1`, otherwise it matches the `CUDA_VISIBLE_DEVICES`.\n",
    "    * `MAX_INPUT_TOKENS` is the maximum allowed input length (expressed in number of tokens), the larger it is, the larger the prompt can be, but also more memory will be consumed.\n",
    "    * `MAX_TOTAL_TOKENS` is the most important value to set as it defines the \"memory budget\" of running clients requests, the larger this value, the larger amount each request will be in your RAM and the less effective batching can be.\n",
    "    * `MAX_BATCH_PREFILL_TOKENS` limits the number of tokens for the prefill operation, as it takes the most memory and is compute bound, it is interesting to limit the number of requests that can be sent.\n",
    "    * `HUGGING_FACE_HUB_TOKEN` is the Hugging Face Hub token, required as [`google/gemma-7b-it`](https://huggingface.co/google/gemma-7b-it) is a gated model.\n",
    "\n",
    "* (optional) **`serving_container_ports`** is the port where the Vertex AI endpoint will be exposed, by default 8080.\n",
    "\n",
    "For more information on the supported `aiplatform.Model.upload` arguments, check its Python reference at https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model#google_cloud_aiplatform_Model_upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-generation-inference-cu124.2-3.ubuntu2204.py311\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"CONTAINER_URI\"))\n",
    "#huggingface-text-generation-inference-cu121.2-2.ubuntu2204.py310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/dali/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"us-docker.pkg.dev\": \"gcloud\",\n",
      "    \"gcr.io\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth configure-docker us-docker.pkg.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/841337720906/locations/us-central1/models/770332140071026688/operations/5437461753883525120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m DISPLAY_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaligemma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#HF_MODEL = \"Salesforce/blip2-opt-2.7b\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#HF_MODEL = \"liuhaotian/llava-v1.5-13b\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#HF_MODEL = \"llava-hf/llava-v1.6-mistral-7b-hf\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#DISPLAY_NAME = \"llava-1.6\"\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43maiplatform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDISPLAY_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserving_container_image_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mus-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-generation-inference-cu121.2-2.ubuntu2204.py310\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserving_container_environment_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMODEL_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHF_MODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHUGGING_FACE_HUB_TOKEN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHF_HUB_ENABLE_HF_TRANSFER\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNUM_SHARD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserving_container_ports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8080\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mwait()\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:863\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    862\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:5043\u001b[0m, in \u001b[0;36mModel.upload\u001b[0;34m(cls, serving_container_image_uri, artifact_uri, model_id, parent_model, is_default_version, version_aliases, version_description, serving_container_predict_route, serving_container_health_route, description, serving_container_command, serving_container_args, serving_container_environment_variables, serving_container_ports, serving_container_grpc_ports, local_model, instance_schema_uri, parameters_schema_uri, prediction_schema_uri, explanation_metadata, explanation_parameters, display_name, project, location, credentials, labels, encryption_spec_key_name, staging_bucket, sync, upload_request_timeout, serving_container_deployment_timeout, serving_container_shared_memory_size_mb, serving_container_startup_probe_exec, serving_container_startup_probe_period_seconds, serving_container_startup_probe_timeout_seconds, serving_container_health_probe_exec, serving_container_health_probe_period_seconds, serving_container_health_probe_timeout_seconds)\u001b[0m\n\u001b[1;32m   5039\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_create_with_lro(\u001b[38;5;28mcls\u001b[39m, lro)\n\u001b[1;32m   5041\u001b[0m model_upload_response \u001b[38;5;241m=\u001b[39m lro\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m-> 5043\u001b[0m this_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_upload_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_upload_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_version_id\u001b[49m\n\u001b[1;32m   5045\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5047\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_create_complete(\u001b[38;5;28mcls\u001b[39m, this_model\u001b[38;5;241m.\u001b[39m_gca_resource, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5049\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m this_model\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/google/cloud/aiplatform/models.py:4503\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model_name, project, location, credentials, version)\u001b[0m\n\u001b[1;32m   4501\u001b[0m \u001b[38;5;66;03m# Create a versioned model_name, if it exists, for getting the GCA model\u001b[39;00m\n\u001b[1;32m   4502\u001b[0m versioned_model_name \u001b[38;5;241m=\u001b[39m ModelRegistry\u001b[38;5;241m.\u001b[39m_get_versioned_name(model_name, version)\n\u001b[0;32m-> 4503\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gca_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversioned_model_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4505\u001b[0m \u001b[38;5;66;03m# Create ModelRegistry with the unversioned resource name\u001b[39;00m\n\u001b[1;32m   4506\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry \u001b[38;5;241m=\u001b[39m ModelRegistry(\n\u001b[1;32m   4507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresource_name,\n\u001b[1;32m   4508\u001b[0m     location\u001b[38;5;241m=\u001b[39mlocation,\n\u001b[1;32m   4509\u001b[0m     project\u001b[38;5;241m=\u001b[39mproject,\n\u001b[1;32m   4510\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[1;32m   4511\u001b[0m )\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:692\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns GAPIC service representation of client class resource.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m        Should not include project and location.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m resource_name \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mfull_resource_name(\n\u001b[1;32m    682\u001b[0m     resource_name\u001b[38;5;241m=\u001b[39mresource_name,\n\u001b[1;32m    683\u001b[0m     resource_noun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_noun,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m     resource_id_validator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_id_validator,\n\u001b[1;32m    690\u001b[0m )\n\u001b[0;32m--> 692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getter_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_RETRY\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/google/cloud/aiplatform_v1/services/model_service/client.py:1043\u001b[0m, in \u001b[0;36mModelServiceClient.get_model\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1043\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/grpc/_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[0;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from huggingface_hub import get_token\n",
    "\n",
    "HF_MODEL = \"google/paligemma-3b-mix-224\" # change this\n",
    "DISPLAY_NAME = \"paligemma\"\n",
    "#HF_MODEL = \"Salesforce/blip2-opt-2.7b\"\n",
    "#HF_MODEL = \"liuhaotian/llava-v1.5-13b\"\n",
    "#HF_MODEL = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
    "#DISPLAY_NAME = \"llava-1.6\"\n",
    "\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/deeplearning-platform-release/gcr.io/huggingface-text-generation-inference-cu121.2-2.ubuntu2204.py310\",\n",
    "    serving_container_environment_variables={\n",
    "        \"MODEL_ID\": HF_MODEL,\n",
    "        \"HUGGING_FACE_HUB_TOKEN\": get_token(),\n",
    "        \"HF_HUB_ENABLE_HF_TRANSFER\": \"1\",\n",
    "        \"NUM_SHARD\": \"1\",\n",
    "    },\n",
    "    serving_container_ports=[8080],\n",
    ")\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = aiplatform.Model.upload(\n",
    "    display_name=\"Llama-Vision-11B\",\n",
    "    serving_container_image_uri=os.getenv(\"CONTAINER_URI\"),\n",
    "    serving_container_environment_variables={\n",
    "        \"MODEL_ID\": \"meta-llama/Llama-3.2-11B-Vision-Instruct\",\n",
    "        \"NUM_SHARD\": \"2\",\n",
    "        \"MAX_INPUT_TOKENS\": \"512\",\n",
    "        \"MAX_TOTAL_TOKENS\": \"1024\",\n",
    "        \"MAX_BATCH_PREFILL_TOKENS\": \"1512\",\n",
    "        \"HF_HUB_ENABLE_HF_TRANSFER\": \"1\",\n",
    "        \"HUGGING_FACE_HUB_TOKEN\": get_token(),\n",
    "        \"MESSAGES_API_ENABLED\": \"true\",\n",
    "    },\n",
    "    serving_container_ports=[8080],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model on Vertex AI Model Registry](./assets/vertex-ai-model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model on Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is registered on Vertex AI, you need to define the endpoint that you want to deploy the model to, and then link the model deployment to that endpoint resource.\n",
    "\n",
    "To do so, you need to call the method `aiplatform.Endpoint.create` to create a new Vertex AI endpoint resource (which is not linked to a model or anything usable yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create(display_name=f\"{DISPLAY_NAME}-endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Vertex AI Endpoint created](./assets/vertex-ai-endpoint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the registered model in an endpoint on Vertex AI.\n",
    "\n",
    "The `deploy` method will link the previously created endpoint resource with the model that contains the configuration of the serving container, and then, it will deploy the model on Vertex AI in the specified instance.\n",
    "\n",
    "Before going into the code, let's quickly review the arguments provided to the `deploy` method:\n",
    "\n",
    "- **`endpoint`** is the endpoint to deploy the model to, which is optional, and by default will be set to the model display name with the `_endpoint` suffix.\n",
    "- **`machine_type`**, **`accelerator_type`** and **`accelerator_count`** are arguments that define which instance to use, and additionally, the accelerator to use and the number of accelerators, respectively. The `machine_type` and the `accelerator_type` are tied together, so you will need to select an instance that supports the accelerator that you are using and vice-versa. More information about the different instances at [Compute Engine Documentation - GPU machine types](https://cloud.google.com/compute/docs/gpus), and about the `accelerator_type` naming at [Vertex AI Documentation - MachineSpec](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec).\n",
    "\n",
    "For more information on the supported `aiplatform.Model.deploy` arguments, you can check its Python reference at https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Model#google_cloud_aiplatform_Model_deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model = model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    machine_type=\"g2-standard-24\",\n",
    "    accelerator_type=\"NVIDIA_L4\",\n",
    "    accelerator_count=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_schemata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: _The Vertex AI endpoint deployment via the `deploy` method may take from 15 to 25 minutes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online predictions on Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can run the online predictions on Vertex AI using the `predict` method, which will send the requests to the running endpoint in the `/predict` route specified within the container following Vertex AI I/O payload formatting.\n",
    "\n",
    "As you are serving a `text-generation` model, you will need to make sure that the chat template, if any, is applied correctly to the input conversation; meaning that `transformers` need to be installed so as to instantiate the `tokenizer` for [`google/gemma-7b-it`](https://huggingface.co/google/gemma-7b-it) and run the `apply_chat_template` method over the input conversation before sending the input within the payload to the Vertex AI endpoint.\n",
    "\n",
    "**Note:** The chat template might not be needed for Gemma-2b/the model PaliGemma is based on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the installation is complete, the following snippet will apply the chat template to the conversation:\n",
    "\n",
    ">**This isn't needed for PaliGemma but might be needed for Gemma-2b/the LM it is based on.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Via Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Within the same session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are willing to run the online prediction within the current session, you can send requests programmatically via the `aiplatform.Endpoint` (returned by the `aiplatform.Model.deploy` method) as in the following snippet:\n",
    "\n",
    "\n",
    "Here, we have listed code to supply images to the model via two different ways: (1) via urls, and (2) from local files. KM has extrapolated this syntax from the TGI docs on huggingface: https://huggingface.co/docs/text-generation-inference/en/basic_tutorials/visual_language_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**URL Based**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/rabbit.png\"\n",
    "url = \"https://people.cs.umu.se/dali/test.png\"\n",
    "\n",
    "output = endpoint.predict(\n",
    "    instances=[\n",
    "        {\n",
    "            \"inputs\":f\"![]({url}) What is in this image?\\n\",\n",
    "            \"parameters\":{\"max_new_tokens\": 100, \"do_sample\": False}\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "# > helmet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"fgqa_hs/images/output.png\"\n",
    "image_path = \"/home/dali/Downloads/rabbit.png\"\n",
    "from PIL import Image\n",
    "\n",
    "# Open an image file\n",
    "with open(image_path, \"rb\") as f:\n",
    "\n",
    "    \n",
    "    image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    #image = f\"data:image/png;base64,{image}\"\n",
    "\n",
    "    output = deployed_model.predict(\n",
    "        instances=[\n",
    "            {\"prompt\": \"Describe this image in detail:\\n\",\"base64_image\":image}\n",
    "        ]\n",
    "    )\n",
    "#> space suit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# is different when image is passed from a local file vs. from an url\n",
    "# even when we use greedy decoding (I think?), strange!\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/841337720906/locations/us-central1/endpoints/8139500961983889408/operations/8933943914583293952\n",
      "Endpoint created. Resource name: projects/841337720906/locations/us-central1/endpoints/8139500961983889408\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/841337720906/locations/us-central1/endpoints/8139500961983889408')\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/841337720906/locations/us-central1/models/4762773209734971392/operations/2599912513663401984\n",
      "Model created. Resource name: projects/841337720906/locations/us-central1/models/4762773209734971392@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/841337720906/locations/us-central1/models/4762773209734971392@1')\n",
      "Deploying model to Endpoint : projects/841337720906/locations/us-central1/endpoints/8139500961983889408\n",
      "Deploy Endpoint model backing LRO: projects/841337720906/locations/us-central1/endpoints/8139500961983889408/operations/7847450504480161792\n",
      "Endpoint model deployed. Resource name: projects/841337720906/locations/us-central1/endpoints/8139500961983889408\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"liuhaotian/llava-v1.5-13b\"\n",
    "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-llava-serve\"\n",
    "\n",
    "def deploy_model(model_id: str) -> tuple[aiplatform.Model, aiplatform.Endpoint]:\n",
    "   \"\"\"Uploads and deploys the model to Vertex AI endpoint for prediction.\"\"\"\n",
    "   model_name = \"llava_1.5\"\n",
    "   endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-endpoint\")\n",
    "   serving_env = {\n",
    "       \"MODEL_ID\": model_id,\n",
    "       \"TS_NUM_WORKERS\": 1,\n",
    "       \"PRECISION_MODE\": \"4bit\",\n",
    "       \"DEPLOY_SOURCE\": \"custom\",\n",
    "   }\n",
    "   # If the model_id is a GCS path, use artifact_uri to pass it to serving docker.\n",
    "   artifact_uri = model_id if model_id.startswith(\"gs://\") else None\n",
    "   model = aiplatform.Model.upload(\n",
    "       display_name=model_name,\n",
    "       serving_container_image_uri=SERVE_DOCKER_URI,\n",
    "       serving_container_ports=[7080],\n",
    "       serving_container_predict_route=\"/predictions/llava_serving\",\n",
    "       serving_container_health_route=\"/ping\",\n",
    "       serving_container_environment_variables=serving_env,\n",
    "       artifact_uri=artifact_uri,\n",
    "   )\n",
    "   deployed_model = model.deploy(\n",
    "       endpoint=endpoint,\n",
    "       machine_type=\"g2-standard-24\",\n",
    "       accelerator_type=\"NVIDIA_L4\",\n",
    "       accelerator_count=2,\n",
    "       deploy_request_timeout=1800,\n",
    "   )\n",
    "   return model, deployed_model, endpoint\n",
    "\n",
    "model, deployed_model, endpoint = deploy_model(model_id=MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': 'What is in this image?', 'base64_image': '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'}]\n",
      "['The image features a rabbit wearing a space suit, standing on a rocky surface.']\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import io\n",
    "import requests\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_remote_image(path):\n",
    "   \"\"\"Downloads a remote image into memory.\"\"\"\n",
    "   response = requests.get(path)\n",
    "   image = Image.open(io.BytesIO(response.content))\n",
    "   return image\n",
    "\n",
    "\n",
    "def image_to_base64(image: Image.Image) -> str:\n",
    "   \"\"\"Converts a PIL image to a base64 string.\"\"\"\n",
    "   buffer = io.BytesIO()\n",
    "   image.save(buffer, format=\"JPEG\")\n",
    "   image_str = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "   return image_str\n",
    "\n",
    "\n",
    "prompt = 'What is in this image?'\n",
    "image_path = 'https://people.cs.umu.se/dali/test.png'\n",
    "\n",
    "\n",
    "image = get_remote_image(image_path)\n",
    "instances = [\n",
    "     {\n",
    "         'prompt': prompt,\n",
    "         'base64_image': image_to_base64(image)\n",
    "     }\n",
    "]\n",
    "preds = endpoint.predict(instances=instances).predictions\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing the following `output`:\n",
    "\n",
    "```\n",
    "Prediction(predictions=['space suit'], deployed_model_id='6484700777808920576', metadata=None, model_version_id='1', model_resource_name='projects/20178026/locations/us-central1/models/1030014796319162368', explanations=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_answers(model, images, questions, gen_config):\n",
    "    assert len(images) == len(questions)\n",
    "\n",
    "    instances = []\n",
    "\n",
    "    #generation_config = {\n",
    "    #    \"max_new_tokens\": 256,\n",
    "    #    \"do_sample\": True,\n",
    "    #    \"top_p\": 0.2,\n",
    "    #    \"temperature\": 0.2,\n",
    "    #}\n",
    "\n",
    "    binarized_images = []\n",
    "    for i, image in enumerate(images):\n",
    "        img = f\"data:image/png;base64,{image}\"\n",
    "        instance = {\"inputs\":f\"![]({img}){questions[i]}\\n\\n\",\n",
    "                \"parameters\": gen_config}\n",
    "        instances.append(instance)\n",
    "    print(len(instances[0][\"inputs\"]))\n",
    "    output = model.predict(\n",
    "        instances=instances\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561582\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Unknown field for DeployedModel: predict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     image \u001b[38;5;241m=\u001b[39m base64\u001b[38;5;241m.\u001b[39mb64encode(f\u001b[38;5;241m.\u001b[39mread())\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     images \u001b[38;5;241m=\u001b[39m [image, image]\n\u001b[0;32m----> 8\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_answers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployed_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is in the image?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIs the animal in the image threatening?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mpredictions:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m, in \u001b[0;36mpredict_answers\u001b[0;34m(model, images, questions, gen_config)\u001b[0m\n\u001b[1;32m     18\u001b[0m     instances\u001b[38;5;241m.\u001b[39mappend(instance)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(instances[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m---> 20\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(\n\u001b[1;32m     21\u001b[0m     instances\u001b[38;5;241m=\u001b[39minstances\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/work/postdoc/multimodal-semantic-signals/semantic-signals-env/lib/python3.12/site-packages/proto/message.py:906\u001b[0m, in \u001b[0;36mMessage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m (key, pb_type) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pb_type_from_key(key)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pb_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown field for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, key)\n\u001b[1;32m    908\u001b[0m     )\n\u001b[1;32m    909\u001b[0m pb_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pb, key)\n\u001b[1;32m    910\u001b[0m marshal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta\u001b[38;5;241m.\u001b[39mmarshal\n",
      "\u001b[0;31mAttributeError\u001b[0m: Unknown field for DeployedModel: predict"
     ]
    }
   ],
   "source": [
    "image_path = \"/home/dali/Downloads/rabbit.png\"\n",
    "\n",
    "generation_config = {\"max_new_tokens\": 100, \"do_sample\": False}\n",
    "\n",
    "with open(image_path, \"rb\") as f:\n",
    "    image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    images = [image, image]\n",
    "    output = predict_answers(deployed_model, \n",
    "                             images, \n",
    "                             [\"What is in the image?\", \"Is the animal in the image threatening?\"], \n",
    "                             generation_config)\n",
    "for prediction in output.predictions:\n",
    "    print(prediction)\n",
    "print(output)\n",
    "#> space suit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation task\n",
    "\n",
    "Based on [https://huggingface.co/docs/google-cloud/main/examples/vertex-ai-notebooks-evaluate-llms-with-vertex-ai](https://huggingface.co/docs/google-cloud/main/examples/vertex-ai-notebooks-evaluate-llms-with-vertex-ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'argument', 'image', 'substitution'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"fgqa_hs\", split='test[:100]')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Is the curtain on the right side or on the left of the picture?',\n",
       " 'answer': 'right',\n",
       " 'argument': 'curtain',\n",
       " 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x334>,\n",
       " 'substitution': ''}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must convert to a pandas dataset in order to use the Vertex Evaluation API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_image(img_path, img_type='jpg'):\n",
    "    \n",
    "    with open(f\"{img_path}\", \"rb\") as f:\n",
    "        image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:image/{img_type};base64,{image}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0. Convert images to base64 representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "df[\"base64_image\"] = df[\"image\"].apply(lambda x: image_to_base64(Image.open(x['path'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer with a single word or concept. Is the blind on the right side or on the left of the picture?'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['prompt'] = df.apply(lambda row: f\"![]({row['img']}) {row['question']}\", axis=1)\n",
    "df['prompt'] = df.apply(lambda row: (row['base64_image'], f\"Answer with a single word or concept. {row['question']}\"), axis=1)\n",
    "\n",
    "df['prompt'][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reference'] = df['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all columns that we do not need for the prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, generation_config=generation_config):\n",
    "\n",
    "    payload = prompt_to_payload(prompt, generation_config)\n",
    "    output = endpoint.predict(instances=[payload])\n",
    "    generated_text = output.predictions[0]\n",
    "    #print(output.predictions)\n",
    "    return generated_text.lower()\n",
    "\n",
    "def prompt_to_payload(prompt, generation_config):\n",
    "    return {\"base64_image\": prompt[0],\"prompt\": prompt[1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = []\n",
    "for row in df['prompt']:\n",
    "    prompt_data.append(prompt_to_payload(row,{}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data.json\", 'w') as f:\n",
    "    for item in prompt_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'right'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(df['prompt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.evaluation import EvalTask\n",
    "from vertexai.generative_models import (Part)\n",
    "# 2. create eval task\n",
    "eval_task = EvalTask(\n",
    "        dataset=df,\n",
    "        metrics=[\"exact_match\"],\n",
    "        experiment=\"multimodal-hypernym-semantics\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-62169d8a-19fb-4a0a-8d95-f74e6cfe1350\" href=\"#view-view-vertex-resource-62169d8a-19fb-4a0a-8d95-f74e6cfe1350\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-62169d8a-19fb-4a0a-8d95-f74e6cfe1350');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/multimodal-hypernym-semantics/runs?project=multimodal-representations');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/multimodal-hypernym-semantics/runs?project=multimodal-representations', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/841337720906/locations/us-central1/metadataStores/default/contexts/multimodal-hypernym-semantics-test-gqa-4a17fc36 to Experiment: multimodal-hypernym-semantics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-40181f19-b07a-461a-9b0a-8b738c7a2299\" href=\"#view-view-vertex-resource-40181f19-b07a-461a-9b0a-8b738c7a2299\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment Run</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-40181f19-b07a-461a-9b0a-8b738c7a2299');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/multimodal-hypernym-semantics/runs/multimodal-hypernym-semantics-test-gqa-4a17fc36?project=multimodal-representations');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/multimodal-hypernym-semantics/runs/multimodal-hypernym-semantics-test-gqa-4a17fc36?project=multimodal-representations', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a total of 100 responses from the custom model function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [02:52<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 100 responses are successfully generated from the custom model function.\n",
      "Multithreaded Batch Inference took: 172.8143997840234 seconds.\n",
      "Computing metrics with a total of 100 Vertex Gen AI Evaluation Service API requests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [06:41<00:00,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 100 metric requests are successfully computed.\n",
      "Evaluation Took:401.9961060429923 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "# 3. run eval task\n",
    "# Note: If the last iteration takes > 1 minute you might need to retry the evaluation\n",
    "exp_results = eval_task.evaluate(\n",
    "        model=generate, experiment_run_name=f\"test-gqa-{str(uuid.uuid4())[:8]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(prompts, generation_config=generation_config):\n",
    "    payloads = [prompt_to_payload(prompt, generation_config) for prompt in prompts]\n",
    "    print(payloads)\n",
    "    output = endpoint.predict(instances=payloads)\n",
    "    generated_texts = output.predictions\n",
    "    #print(output.predictions)\n",
    "    return [pred.lower() for pred in generated_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "predictions = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df['question'])):\n",
    "    pred = generate([row['base64_image'], row['question']])        \n",
    "    predictions.append(pred)\n",
    "df['online_responses'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['online_responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "print(exp_results.summary_metrics)\n",
    "print(f\"{exp_results.summary_metrics['exact_match/mean']}\")\n",
    "results[\"test\"] = exp_results.summary_metrics[\"exact_match/mean\"]\n",
    "\n",
    "for prompt_name, score in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{prompt_name}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def get_url_from_gcs(gcs_uri: str) -> str:\n",
    "    # converts GCS uri to url for image display.\n",
    "    url = \"https://storage.googleapis.com/\" + gcs_uri.replace(\"gs://\", \"\").replace(\n",
    "        \" \", \"%20\"\n",
    "    )\n",
    "    return url\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if isinstance(content, Image):\n",
    "            display_images([content])\n",
    "        elif isinstance(content, Part):\n",
    "            url = get_url_from_gcs(content.file_data.file_uri)\n",
    "            IPython.display.display(load_image_from_url(url))\n",
    "        else:\n",
    "            print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_results.metrics_table[['question', 'response', 'reference', 'argument', 'substitution', 'exact_match/score']]\n",
    "#exp_results.metrics_table[['question', 'response', 'reference', 'argument', 'substitution', 'exact_match/score', 'rouge/score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = exp_results.metrics_table[['question', 'response', 'reference', 'argument', 'substitution', 'exact_match/score']]\n",
    "#result_df = exp_results.metrics_table[['question', 'response', 'reference', 'argument', 'substitution', 'exact_match/score', 'rouge/score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('llava-100-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_base_questions = result_df[result_df['substitution'] == ''].groupby('argument').agg({\n",
    "    'exact_match/score': 'mean',\n",
    "  #  'rouge/score': 'mean'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_base_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating over all substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_substitutions = result_df[result_df['substitution'] != ''].groupby('argument').agg({\n",
    "    'exact_match/score': 'mean',\n",
    "#    'rouge/score': 'mean'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregated_substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "aggregated_combined = aggregated_base_questions.rename(columns={'exact_match/score': 'base/exact_match/score',\n",
    "                                                                #'rouge/score':'base/rouge/score'\n",
    "                                                               })\n",
    "\n",
    "# Merge the two dataframes on a common key (in this case, 'key')\n",
    "aggregated_combined = pd.merge(aggregated_combined, aggregated_substitutions, on='argument', how='left')\n",
    "\n",
    "# Fill empty values with 0.0\n",
    "aggregated_combined = aggregated_combined.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_results.metrics_table['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "from PIL import Image as PImage\n",
    "\n",
    "imgs = set([img['path'] for img in df['image'][:10]])\n",
    "\n",
    "for image in imgs:\n",
    "    #Image(filename=image['path'])\n",
    "    img = mpimg.imread(image)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    img = image_to_base64(PImage.open(image))\n",
    "    output = generate([img, \"What is in the image?\"])\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "image = mpimg.imread(image['path'])\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch inference\n",
    "\n",
    "Below is example code from the GCP documentation found at (https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions)[https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions]\n",
    "\n",
    "Also check (https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/generative_ai/batch_eval_llm.ipynb)[https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/generative_ai/batch_eval_llm.ipynb]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_prediction_job_dedicated_resources_sample(\n",
    "    model,\n",
    "    job_display_name: str,\n",
    "    gcs_source,\n",
    "    gcs_destination: str,\n",
    "    machine_type=\"g2-standard-24\", #$0.8129 USD / hour\n",
    "    accelerator_type=\"NVIDIA_L4\", #$0.644046 USD / hour\n",
    "    accelerator_count=2,\n",
    "    instances_format: str = \"jsonl\",\n",
    "    starting_replica_count: int = 1,\n",
    "    max_replica_count: int = 1,\n",
    "    sync: bool = True,\n",
    "):\n",
    "\n",
    "\n",
    "    batch_prediction_job = model.batch_predict(\n",
    "        job_display_name=job_display_name,\n",
    "        gcs_source=gcs_source,\n",
    "        gcs_destination_prefix=gcs_destination,\n",
    "        instances_format=instances_format,\n",
    "        starting_replica_count=starting_replica_count,\n",
    "        max_replica_count=max_replica_count,\n",
    "        \n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        sync=sync,\n",
    "    )\n",
    "\n",
    "    batch_prediction_job.wait()\n",
    "\n",
    "    print(batch_prediction_job.display_name)\n",
    "    print(batch_prediction_job.resource_name)\n",
    "    print(batch_prediction_job.state)\n",
    "    return batch_prediction_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_job = create_batch_prediction_job_dedicated_resources_sample(\n",
    "    model,\n",
    "        job_display_name=\"batch-llava-test-100\",\n",
    "        gcs_source=\"gs://multimodal-representations-eval-data/data.jsonl\",\n",
    "        gcs_destination=\"gs://multimodal-representations-eval-data/\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource clean-up (DEFINITELY DO THIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can already release the resources that you've created as follows, to avoid unnecessary costs:\n",
    "\n",
    "* `deployed_model.undeploy_all` to undeploy the model from all the endpoints.\n",
    "* `deployed_model.delete` to delete the endpoint/s where the model was deployed gracefully, after the `undeploy_all` method.\n",
    "* `model.delete` to delete the model from the registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model.undeploy_all()\n",
    "deployed_model.delete()\n",
    "model.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also remove those from the Google Cloud Console following the steps:\n",
    "\n",
    "* Go to Vertex AI in Google Cloud\n",
    "* Go to Deploy and use -> Online prediction\n",
    "* Click on the endpoint and then on the deployed model/s to \"Undeploy model from endpoint\"\n",
    "* Then go back to the endpoint list and remove the endpoint\n",
    "* Finally, go to Deploy and use -> Model Registry, and remove the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable APIs\n",
    "\n",
    "!gcloud services disable aiplatform.googleapis.com\n",
    "!gcloud services disable compute.googleapis.com\n",
    "!gcloud services disable container.googleapis.com\n",
    "!gcloud services disable containerregistry.googleapis.com\n",
    "!gcloud services disable containerfilesystem.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLEASE ALSO MANUALLY ENSURE ALL APIS ARE DISABLED ON GCP AFTER THIS IS DONE!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an image from Google Cloud Storage\n",
    "# Load from local file\n",
    "from vertexai.generative_models import Image as V_Image\n",
    "\n",
    "gen_model = GenerativeModel(\"paligemma\")\n",
    "\n",
    "image = V_Image.load_from_file(df['image'][0]['path'])\n",
    "\n",
    "# Prepare contents\n",
    "prompt = \"Describe this image?\"\n",
    "contents = [image, prompt]\n",
    "\n",
    "response = gen_model.generate_content(contents)\n",
    "\n",
    "print(\"-------Prompt--------\")\n",
    "print_multimodal_prompt(contents)\n",
    "\n",
    "print(\"\\n-------Response--------\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = aiplatform.Endpoint.list()\n",
    "for i in endpoints:\n",
    "        i.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatives for PaliGemma\n",
    "\n",
    "https://ai.google.dev/gemma/docs/paligemma/inference-with-keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
